
1 发现 kafa 的 0 拷贝 就是 linux操作系统中 的 io 操作 和内存的结合


2 学了spark 之后发现 spark 处理 rdd 的过程跟 看到的jvm 即时编译中的 把数据转化
为内存中额模块 进行重排序计算 的原理好像很类似 

jvm即时编译也是生成中间图，在对中间图进行优化，不过中间图这里的数据是不是元数据呢？

这些又跟linux 内存操作相关么？


4 发现 kafka 和rockermaq  这些消息中间件 很像 怎么选择合适的呢 ？
一方面业界达成的共识 ，
有人已经做过测试 ，字节也可以重新测试  
中间过程 比如消息的大小 和 过程的管理 文件的保存等
跟linux操作系统有很大的关系   


5 学习了linux进程和线程  发现spark 中就是在进程中生成线程 ，可以进一步好好的学习
进程和线程是怎么产生的 ，怎么分配资源的，内存 cpu  


6 如果和利用操作系统的cpu资源  

tomcate jvm 设置的时候只是设置了堆内存，所以我们只是管理了系统的内存一个方面，当发生oom的时候
就是挂掉了

但是如果系统的瓶颈不是内存  而是 io cpu 和 net的时候 我们可以通过jvm来管理吗？


还有容器docker 的cgropu 可以启到限制资源的方法 


如果我们在一台机器上只部署一个tomcate 只是管理了内存 当cpu高的时候或者net io 出问题时候没关系我们可以理解为
这台机器上就是只有一个进程

可是当这台机器上不可能只有一个jvm进程 虽然我们队内存进行了管理，但是如果cpu io net 都被这个进程
占据 那会带来什么样的后果呢  

7
学了 mysql 之后
写sql的时候 会想到 是否加锁了，是否是大事务，是否会影响到数据库的性能，是否更好的利用了操作系统的资源
网络 io cpu 
查询的时候是否产生了数据不一致 
是否可以更快地查询  

8 学了linxu之后 和多线程 大数据
感觉写代码的时候
会想到 可以利用多线程 异步执行 更好的利用系统的资源 

还有异步执行之后怎么控制线程的同步 分工 互斥  整理  


还有处理数据的时候思路和 mapreduce 一样 

还有算法 利用了短发的分之思想  以及用hashmap 时间复杂度为o1的情况
但是没有考虑到空间复杂度的提高

list 是应用类型 在内存中到底是怎么存储了 深浅拷贝 


总之 写代码 考虑问题的境界不一样了。



